{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe8XmJPpzDKw",
        "outputId": "dc94d87b-6020-481b-8f17-473708b1fa80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 97 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 58.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install sumy --quiet\n",
        "!pip install nltk --quiet\n",
        "\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from sumy.nlp.tokenizers import Tokenizer                                       # Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser                              # Pasrer\n",
        "\n",
        "from sumy.summarizers.luhn import LuhnSummarizer as Luhn                        # Luhn\n",
        "from sumy.summarizers.lsa import LsaSummarizer as LSA                           # LSA Summarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer as LexRank              # Lex-Rank\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer as TextRank           # Text-Rank\n",
        "from sumy.summarizers.sum_basic import SumBasicSummarizer as SumBasic           # Sum-Basic\n",
        "from sumy.summarizers.kl import KLSummarizer as KLSum                           # KL-Sum\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summaries(dataset, sentence_count):\n",
        "  '''\n",
        "  Input  : Dataset\n",
        "  Process: Extracts Abstracts, Generates Seven Summaries and Append\n",
        "  Returns: Combined Summaries and All Individual Summaries as Lists\n",
        "  '''\n",
        "  # Placeholders\n",
        "  combined_summaries = []\n",
        "  luhn_summaries = [] \n",
        "  lexrank_summaries = []\n",
        "  textrank_summaries = []\n",
        "  sumbasic_summaries = []\n",
        "  kl_sum_summaries = []\n",
        "  #edmundson_summaries = []\n",
        "  #ed_title_summaries = []  \n",
        "\n",
        "  abstract_list = list(dataset['Abstract'])\n",
        "  count = 1\n",
        "\n",
        "  for data in abstract_list:\n",
        "\n",
        "    # Parse and Tokenize\n",
        "    parser = PlaintextParser.from_string(data, Tokenizer(\"english\"))\n",
        "\n",
        "    # Luhn Summarizer\n",
        "    luhn_text = ''\n",
        "    luhn = Luhn()\n",
        "    luhn_summary = luhn(parser.document, sentence_count)\n",
        "    for sent in luhn_summary:\n",
        "      luhn_text += str(sent)\n",
        "    luhn_summaries.append(luhn_text)\n",
        "\n",
        "    # LexRank Summarizer\n",
        "    lex_text = ''\n",
        "    lex = LexRank()\n",
        "    lex_summary = lex(parser.document, sentence_count)\n",
        "    for sent in lex_summary:\n",
        "      lex_text += str(sent)\n",
        "    lexrank_summaries.append(lex_text)\n",
        "\n",
        "    # TextRank Summarizer\n",
        "    textrank_text = ''\n",
        "    textrank = TextRank()\n",
        "    textrank_summary = textrank(parser.document, sentence_count)\n",
        "    for sent in textrank_summary:\n",
        "      textrank_text += str(sent)\n",
        "    textrank_summaries.append(textrank_text)\n",
        "\n",
        "    # SumBasic Summarizer\n",
        "    sum_basic_text = ''\n",
        "    sumbasic = SumBasic()\n",
        "    sumbasic_summary = sumbasic(parser.document, sentence_count)\n",
        "    for sent in sumbasic_summary:\n",
        "      sum_basic_text += str(sent)\n",
        "    sumbasic_summaries.append(sum_basic_text)\n",
        "\n",
        "    # KLSum Summarizer\n",
        "    kl_text = ''\n",
        "    kl = KLSum()\n",
        "    kl_summary = kl(parser.document, sentence_count)\n",
        "    for sent in kl_summary:\n",
        "      kl_text += str(sent)\n",
        "    kl_sum_summaries.append(kl_text)\n",
        "\n",
        "    # Concatenation of Summaries\n",
        "    combined_text = luhn_text + lex_text + textrank_text + sum_basic_text + kl_text\n",
        "    combined_summaries.append(combined_text)\n",
        "\n",
        "    # Progress\n",
        "    if (count%1000 == 0):\n",
        "      print('Summarization Complete for Abstract ID = {}'.format(count))\n",
        "    count += 1\n",
        "\n",
        "  return combined_summaries, luhn_summaries, lexrank_summaries, textrank_summaries, sumbasic_summaries, kl_sum_summaries\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data Preparation into Pandas Dataframe for Final Summarization Model Input and Other Tasks\n",
        "def get_data(dataset, combined_summaries, luhn_summaries, lexrank_summaries, textrank_summaries, sumbasic_summaries, kl_sum_summaries, get_excel = True):\n",
        "  '''\n",
        "  Generate Dataframe with Title and All Summaries and return final DF and an Excel File\n",
        "  '''\n",
        "  title = list(dataset['Title'])\n",
        "\n",
        "  raw_dataframe = {'Combined Abstract'   : combined_summaries, \n",
        "                   'Luhn Summaries'      : luhn_summaries,\n",
        "                   'LexRank Summaries'   : lexrank_summaries,\n",
        "                   'TextRank Summaries'  : textrank_summaries,\n",
        "                   'SumBasic Summaries'  : sumbasic_summaries,\n",
        "                   'KL Summaries'        : kl_sum_summaries,\n",
        "                   'Title'               : title}\n",
        "  df = pd.DataFrame(raw_dataframe, columns = ['Combined Abstract',\n",
        "                                              'Luhn Summaries',\n",
        "                                              'LexRank Summaries', \n",
        "                                              'TextRank Summaries',\n",
        "                                              'SumBasic Summaries',\n",
        "                                              'KL Summaries',\n",
        "                                              'Title'])\n",
        "  if (get_excel == True):\n",
        "    df.to_excel(\"Summary_Dataset_Complete.xlsx\")\n",
        "    print('Excel File Created and Saved in Local Storage.')\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "HtjfQcBWzNLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "#num_examples   = 10000\n",
        "sentence_count = 2\n",
        "\n",
        "# Data Loading\n",
        "drive.mount('/content/drive')\n",
        "file = '/content/drive/MyDrive/Title Generation NLP/Dataset/Summary_Dataset_Complete.xlsx' \n",
        "df = pd.read_excel(file, names = ['Abstract', 'Domain_Label', 'Title'])\n",
        "df = df.drop(['Domain_Label'], axis=1)\n",
        "#df = df[:num_examples]\n",
        "\n",
        "# Summarization\n",
        "combines, luhns, lexranks, textranks, sumbasics, kl_sums = get_summaries(df, sentence_count)\n",
        "\n",
        "# Dataset Preparation (Download Excel from Local Storage of Colab)\n",
        "final_data_frame = get_data(df, combines, luhns, lexranks, textranks, sumbasics, kl_sums, get_excel = True)\n",
        "final_data_frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6elJCmbCzNQa",
        "outputId": "e1b23053-903f-49d0-c098-ab2c940451e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Summarization Complete for Abstract ID = 1000\n",
            "Summarization Complete for Abstract ID = 2000\n",
            "Summarization Complete for Abstract ID = 3000\n",
            "Summarization Complete for Abstract ID = 4000\n",
            "Summarization Complete for Abstract ID = 5000\n",
            "Summarization Complete for Abstract ID = 6000\n",
            "Summarization Complete for Abstract ID = 7000\n",
            "Summarization Complete for Abstract ID = 8000\n",
            "Summarization Complete for Abstract ID = 9000\n",
            "Summarization Complete for Abstract ID = 10000\n",
            "Summarization Complete for Abstract ID = 11000\n",
            "Summarization Complete for Abstract ID = 12000\n",
            "Summarization Complete for Abstract ID = 13000\n",
            "Summarization Complete for Abstract ID = 14000\n",
            "Summarization Complete for Abstract ID = 15000\n",
            "Summarization Complete for Abstract ID = 16000\n",
            "Summarization Complete for Abstract ID = 17000\n",
            "Summarization Complete for Abstract ID = 18000\n",
            "Summarization Complete for Abstract ID = 19000\n",
            "Summarization Complete for Abstract ID = 20000\n",
            "Summarization Complete for Abstract ID = 21000\n",
            "Summarization Complete for Abstract ID = 22000\n",
            "Summarization Complete for Abstract ID = 23000\n",
            "Summarization Complete for Abstract ID = 24000\n",
            "Summarization Complete for Abstract ID = 25000\n",
            "Summarization Complete for Abstract ID = 26000\n",
            "Summarization Complete for Abstract ID = 27000\n",
            "Summarization Complete for Abstract ID = 28000\n",
            "Summarization Complete for Abstract ID = 29000\n",
            "Summarization Complete for Abstract ID = 30000\n",
            "Summarization Complete for Abstract ID = 31000\n",
            "Summarization Complete for Abstract ID = 32000\n",
            "Summarization Complete for Abstract ID = 33000\n",
            "Summarization Complete for Abstract ID = 34000\n",
            "Summarization Complete for Abstract ID = 35000\n",
            "Summarization Complete for Abstract ID = 36000\n",
            "Summarization Complete for Abstract ID = 37000\n",
            "Summarization Complete for Abstract ID = 38000\n",
            "Summarization Complete for Abstract ID = 39000\n",
            "Summarization Complete for Abstract ID = 40000\n",
            "Summarization Complete for Abstract ID = 41000\n",
            "Excel File Created and Saved in Local Storage.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       Combined Abstract  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                          Luhn Summaries  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                       LexRank Summaries  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                      TextRank Summaries  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                      SumBasic Summaries  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                            KL Summaries  \\\n",
              "0      We propose an architecture for VQA which utili...   \n",
              "1      In this work we present a model based on recur...   \n",
              "2      We introduce the multiresolution recurrent neu...   \n",
              "3      In Natural Language Processing NLP it is hard ...   \n",
              "4      The system consists of an ensemble of natural ...   \n",
              "...                                                  ...   \n",
              "40995  We study the complexity of learning and approx...   \n",
              "40996  We consider the problem of multiple users targ...   \n",
              "40997  In this paper we compare and analyze clusterin...   \n",
              "40998  When using CAD there is often a choice for the...   \n",
              "40999  To deal with this problem we investigate the u...   \n",
              "\n",
              "                                                   Title  \n",
              "0       Dual Recurrent Attention Units for Visual Que...  \n",
              "1       Sequential Short Text Classification with Rec...  \n",
              "2       Multiresolution Recurrent Neural Networks An ...  \n",
              "3       Learning what to share between loosely relate...  \n",
              "4                  A Deep Reinforcement Learning Chatbot  \n",
              "...                                                  ...  \n",
              "40995   Nearly Tight Bounds on ell Approximation of S...  \n",
              "40996    Concurrent bandits and cognitive radio networks  \n",
              "40997   A Comparison of Clustering and Missing Data M...  \n",
              "40998   Applying machine learning to the problem of c...  \n",
              "40999   A Multi Level Data Fusion Approach for Speake...  \n",
              "\n",
              "[41000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8960035a-a1e2-4ea1-9c9f-0cba6085b4d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combined Abstract</th>\n",
              "      <th>Luhn Summaries</th>\n",
              "      <th>LexRank Summaries</th>\n",
              "      <th>TextRank Summaries</th>\n",
              "      <th>SumBasic Summaries</th>\n",
              "      <th>KL Summaries</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>Dual Recurrent Attention Units for Visual Que...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>In this work we present a model based on recur...</td>\n",
              "      <td>Sequential Short Text Classification with Rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>Multiresolution Recurrent Neural Networks An ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>In Natural Language Processing NLP it is hard ...</td>\n",
              "      <td>Learning what to share between loosely relate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>The system consists of an ensemble of natural ...</td>\n",
              "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40995</th>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>We study the complexity of learning and approx...</td>\n",
              "      <td>Nearly Tight Bounds on ell Approximation of S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40996</th>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>We consider the problem of multiple users targ...</td>\n",
              "      <td>Concurrent bandits and cognitive radio networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40997</th>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>In this paper we compare and analyze clusterin...</td>\n",
              "      <td>A Comparison of Clustering and Missing Data M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40998</th>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>When using CAD there is often a choice for the...</td>\n",
              "      <td>Applying machine learning to the problem of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40999</th>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>To deal with this problem we investigate the u...</td>\n",
              "      <td>A Multi Level Data Fusion Approach for Speake...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8960035a-a1e2-4ea1-9c9f-0cba6085b4d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8960035a-a1e2-4ea1-9c9f-0cba6085b4d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8960035a-a1e2-4ea1-9c9f-0cba6085b4d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWKdYlZFzNWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cX3NxUM0zNcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpD0YeNezNhP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}